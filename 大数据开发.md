### 名词说明

- HBase是文件系统之上的分布式数据库
- Spark是分布式计算框架
- MapReduce是个计算模型
- KFS是分布式文件系统
- 写时模式：数据在写入之前，需要定义好数据的Schema，数据按照Schema的定义写入。
- 读时模式：数据在写入的时候，不需要定义Schema，在需要的时候使用schema定义它。
- ODS：Operation Data Source，数据准备区，贴源层。直接接入源数据：业务数据库、埋点日志、消息队列等。
- DWD：Data Warehouse Details，数据细节层，业务层和数据仓库层的隔离层，保持和ODS层相同的颗粒度；进行数据清洗和规范化操作：去空/脏数据、离群值等。
- DWM：Data Warehouse Middle，数据中间层，在DWD的基础上进行轻微地聚合操作，算出相应的统计指标；聚合之后会生成【中间表】。
- DWS：Data Warehouse Service，数据服务层，在DWS的基础上，整合汇总成一个主体的数据服务层；汇总结果通常是【宽表】，用于OLAP、数据分发等。
- ADS：Application Data Service，数据应用层，主要是提供给数据产品和数据分析使用的数据，一般会存放在ES、Redis、PostgreSql等系统中供线上系统使用；也可能存放在hive或Druid中，供数据分析和数据挖掘使用，比如常用的数据报表就是存在这里的。
- OLAP：On-Line Analytical Processing，联机分析处理，主要用于支持企业决策管理分析，它可以发现数据、报告查看功能、复杂的分析计算以及预测性“假设”场景、预算计划、预测计划。

### 大数据组件

| 组件名称  | 组件功能介绍                                                 |
| --------- | ------------------------------------------------------------ |
| Flume-ng  | Flume是一个分布式、高可靠、高可用的海量日志聚合系统。        |
| YARN      | 新一代资源管理框架，允许多个应用集群同时高效地运行在一个物理集群上。 |
| HDFS      | Apache Hadoop分布式文件系统（HDFS）是Hadoop应用程序使用的主要存储系统。HDFS创建了多个数据块副本 并将他们分布在整个集群的计算主机上，以启用高可靠且极其快速的计算功能 |
| HBase     | 非关系型分布式NoSQL数据库，与传统数据库相比，采用列的方式进行存储，具有高加载、低延迟的特性，用于千亿级数据的快速查询。 |
| Hive      | **语法转义(SQL->MR)**，基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能， 可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的 MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。 |
| Presto    | **便捷、统一**，Presto是一个开源的分布式SQL查询引擎 ，适用于交互式查询，数据量支持GB到PB字节。Presto的设计和编写完 全是为了解决如Face book这样规模的商业数据库的交互式分析和处理速度的问题，它拥有比Hive更高的执行效率， 并针对不同的数据源提供了对应的连接器，用于实现统一的ETL。 |
| Oozie     | Oozie是一个工作流调度引擎，可按时间或数据变化触发运行，是集群中管理数据作业的工作流协调服务 |
| Sqoop     | 主要用于在Hadoop（Hive）与传统的数据库（MySQL、PostgreSQL….）间进行数据的传递，可以将一个关系型数 据库（如MySQL、Oracle、PostgreSQL等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导出到关系 型数据库中。 |
| Zookeeper | 一个开放源码的分布式应用服务协调服务，是谷歌的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。他 是一个为分布式应用提供一致性服务的软件，提供的功能包括配置维护、域名维护、分布和同步、组服务等。 |
| Impala    | Impala为存储在HDFS和Hbase中的数据提供了一个实时SQL查询接口。Impala需要Hive服务，并共享HiveMetastore。 |
| Solr      | 一个独立的企业级搜索应用服务器，它对外提供类似于WebService的API接口。用户可以通过HTTP请求，向搜索 引擎服务提交一定格式的XML文件，生成索引，也可以通过HttpGet操作提出查找请求，并得到XML格式的返回结 果。 |
| Titan     | 基于图的数据库，通过节点和边的建立关系网络。                 |
| Kafka     | 一种高吞吐量的分布式发布订阅消息系统，可以处理网站中的所有动作流数据。 |
| Storm     | Apache Storm是一个分布式、可靠、容错的数据流处理系统，适用于实时分析、在线机器学习、连续计算、分布 式RPC、分布式ETL等 |



### 实时计算

1. Storm：低延迟
2. Spark Streaming：高吞吐、准确性
3. Flink：操作简单、语义窗口/多时间窗口



### 数据单位

```
1B（Byte字节）=8bit
1KB (Kilobyte 千字节)=1024B，
1MB (Mega byte 兆字节 简称“兆”)=1024KB，
1GB (Giga byte 吉字节 又称“千兆”)=1024MB，
1TB (Tera byte 万亿字节 太字节)=1024GB，其中1024=2^10 ( 2 的10次方)，
1PB（Peta byte 千万亿字节 拍字节）=1024TB，
1EB（Exa byte 百亿亿字节 艾字节）=1024PB，
1ZB (Zetta byte 十万亿亿字节 泽字节)= 1024 EB,
1YB (Yotta byte 一亿亿亿字节 尧字节)= 1024 ZB,
1BB (Bronto byte 一千亿亿亿字节)= 1024 YB
1NB(Nona byte )= 1024BB
1DB(Dogga byte)= 1024NB
```



### 虚拟机配置

#### MySQL配置

```mysql
# ERROR 1819 (HY000): Your password does not satisfy the current policy requirements
set global validate_password_policy=0;
set global validate_password_length=6;

#重置密码
alter user user() identified by "hadoop";

#授权
grant all privileges on *.* to 'root'@'%' identified by 'hadoop' with grant option;
flush privileges;
```

#### 虚拟机启动脚本

```shell
#zookeeper
/opt/module/zookeeper-3.4.9/bin/zkServer.sh start
/opt/module/zookeeper-3.4.9/bin/zkServer.sh status

#mysql
rpm -qa |grep mysql
rpm -qa |grep postfix
rpm -qa |grep mariadb
rpm -e --nodeps [查找到的rpm包] #卸载包

yum -y install libaio 
yum -y install net-tools 
yum -y install perl

rpm -ivh mysql-community-common-5.7.36-1.el7.x86_64.rpm 
rpm -ivh mysql-community-libs-5.7.36-1.el7.x86_64.rpm 
rpm -ivh mysql-community-client-5.7.36-1.el7.x86_64.rpm 
rpm -ivh mysql-community-server-5.7.36-1.el7.x86_64.rpm

hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar pi 20 20
```



#### 配置core-site.xml

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://ns</value> 
</property>
<!-- 指定 Hadoop 数据存放目录 -->
<property>
  <name>hadoop.tmp.dir</name>
  <value>/opt/module/hadoop-2.7.3/data</value> 
</property>
<!-- 指定 zookeeper 的连接地址 -->
<property>
  <name>ha.zookeeper.quorum</name>
  <value>hadoop001:2181,hadoop002:2181,hadoop003:2181</value> 
</property>
```



#### 配置hdsf-site.xml

```xml
<!-- 绑定在 Zookeeper 上注册的节点名 -->
 <property>
 <name>dfs.nameservices</name>
 <value>ns</value>
 </property>
 <!-- ns 集群下有两个 namenode，分别为 nn1, nn2 -->
 <property>
 <name>dfs.ha.namenodes.ns</name>
 <value>nn1,nn2</value>
   </property>
 <!--nn1 的 RPC 通信-->
 <property>
 <name>dfs.namenode.rpc-address.ns.nn1</name>
 <value>hadoop001:9000</value>
 </property>
 <!--nn1 的 http 通信-->
 <property>
 <name>dfs.namenode.http-address.ns.nn1</name>
 <value>hadoop001:50070</value>
 </property>
 <!-- nn2 的 RPC 通信地址 -->
 <property>
 <name>dfs.namenode.rpc-address.ns.nn2</name>
 <value>hadoop002:9000</value>
 </property>
 <!-- nn2 的 http 通信地址 -->
 <property>
 <name>dfs.namenode.http-address.ns.nn2</name>
 <value>hadoop002:50070</value>
 </property>
 <!--指定 namenode 的元数据在 JournalNode 上存放的位置，这样，namenode2 可以
从 journalnode 集群里的指定位置上获取信息，达到热备效果-->
 <property>
 <name>dfs.namenode.shared.edits.dir</name>
 <value>qjournal://hadoop001:8485;hadoop002:8485;hadoop003:8485/ns</value>
 </property>
 <!-- 指定 JournalNode 在本地磁盘存放数据的位置 -->
 <property>
 <name>dfs.journalnode.edits.dir</name>
 <value>/opt/module/hadoop-2.7.3/data/journal</value>
 </property>
 <!-- 开启 NameNode 故障时自动切换 -->
 <property>
 <name>dfs.ha.automatic-failover.enabled</name>
 <value>true</value>
 </property>
 <!-- 配置失败自动切换实现方式 -->
 <property>
 <name>dfs.client.failover.proxy.provider.ns</name>

<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
 </property>
 <!-- 配置隔离机制 -->
 <property>
 <name>dfs.ha.fencing.methods</name>
 <value>sshfence</value>
 </property>
 <!-- 使用隔离机制时需要 ssh 免登陆 -->
 <property>
 <name>dfs.ha.fencing.ssh.private-key-files</name>
 <value>/root/.ssh/id_rsa</value>
   </property>
 <!--配置 namenode 存放元数据的目录，可以不配置，如果不配置则默认放到
hadoop.tmp.dir 下-->
 <property>
 <name>dfs.namenode.name.dir</name>
 <value>file:///opt/module/hadoop-2.7.3/data/hdfs/name</value>
 </property>
 <!--配置 datanode 存放元数据的目录，可以不配置，如果不配置则默认放到
hadoop.tmp.dir 下-->
 <property>
 <name>dfs.datanode.data.dir</name>
 <value>file:///opt/module/hadoop-2.7.3/data/hdfs/data</value>
 </property>
 <!--配置副本数量-->
 <property>
 <name>dfs.replication</name>
 <value>3</value>
 </property>
 <!--设置用户的操作权限，false 表示关闭权限验证，任何用户都可以操作-->
 <property>
 <name>dfs.permissions</name>
 <value>false</value>
 </property>
```



#### 配置mapred-site.xml

```xml
<property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>
```



#### 配置yarn-site.xml 

```xml
<!--配置 yarn 的高可用-->
 <property>
 <name>yarn.resourcemanager.ha.enabled</name>
 <value>true</value>
   </property>
 <!--指定两个 resourcemaneger 的名称-->
 <property>
 <name>yarn.resourcemanager.ha.rm-ids</name>
 <value>rm1,rm2</value>
 </property>
 <!--配置 rm1 的主机-->
 <property>
 <name>yarn.resourcemanager.hostname.rm1</name>
 <value>hadoop001</value>
 </property>
 <!--配置 rm2 的主机-->
 <property>
 <name>yarn.resourcemanager.hostname.rm2</name>
 <value>hadoop003</value>
 </property>
 <!--开启 yarn 恢复机制-->
 <property>
 <name>yarn.resourcemanager.recovery.enabled</name>
 <value>true</value>
 </property>
 <!--执行 rm 恢复机制实现类-->
 <property>
 <name>yarn.resourcemanager.store.class</name>

<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
 </property>
 <!--配置 zookeeper 的地址-->
 <property>
 <name>yarn.resourcemanager.zk-address</name>
 <value>hadoop001:2181,hadoop002:2181,hadoop003:2181</value>
 </property>
 <!--执行 yarn 集群的别名-->
 <property>
 <name>yarn.resourcemanager.cluster-id</name>
 <value>ns-yarn</value>
 </property>
 <!-- 指定 nodemanager 启动时加载 server 的方式为 shuffle server -->
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
 <!-- 指定 resourcemanager 地址 -->
 <property>
 <name>yarn.resourcemanager.hostname</name>
 <value>hadoop003</value>
 </property>
```

#### 配置hive-env.sh

```shell
export JAVA_HOME=/opt/module/jdk1.8.0_231 
export HADOOP_HOME=/opt/module/hadoop-2.7.3 
export HIVE_HOME=/opt/module/apache-hive-3.1.2-bin 
export HIVE_CONF_DIR=$HIVE_HOME/conf 
export HIVE_AUX_JARS_PATH=$HIVE_HOME/lib
```

#### 配置sqoop-env.sh

```shell
export HADOOP_COMMON_HOME=/opt/module/hadoop-2.7.3 
export HADOOP_MAPRED_HOME=/opt/module/hadoop-2.7.3 
export HIVE_HOME=/opt/module/apache-hive-3.1.2-bin

sqoop import --connect jdbc:mysql://192.168.5.102:3306/test --username root --password root1234 --table stu --hive-import --hive-overwrite --create-hive-table --delete-target-dir --hive-database default --hive-table ods_test_stu -m 1
```

#### 关闭yarn内存检查

```xml
<!-- 关闭yarn内存检查 --> 
<property>
	<name>yarn.nodemanager.pmem-check-enabled</name>
	<value>false</value> 
</property>
<property> 
  <name>yarn.nodemanager.vmem-check-enabled</name> 
  <value>false</value> 
</property>
```



### 问题合集

#### 1、HDFS读写流程。

```
1、通过Client与NameNode交互，获取到文件位置信息-》与DataNode交互，读取数据
2、通过Client上传文件，Client将文件切成一个一个的Block，然后进行上传-》与NameNode交互，获取到文件位置信息-》与DataNode交互，写入数据
```

#### 2、HDFS中NameNode和DataNode的作用。

```
NameNode：
1、管理HDFS的名称空间。
2、配置副本策略。
3、管理数据块(Block)映射信息。
4、处理客户端读写请求。

DataNode：
1、存储实际的数据块。
2、执行数据块的读写操作。
```

#### 3、SecondaryNameNode的作用？或者NameNode的启动过程。

```
SecondaryNameNode的作用：
1、辅助NameNode，分担工作量。比如定期合并Fsimgae和Edits，并推送给NameNode。
2、紧急情况下，辅助恢复NameNode。
```

#### 4、什么情况下HDFS集群会进入安全模式？有哪些解决办法？

```
Hadoop为了保证集群中的数据块的安全性，集群启动的时候，会首先进入安全模式，处于安全模式的系统会检查数据块的完整性。当处于安全模式下，文件系统只接受读取的操作，不接受删除和修改等变更请求。当整个系统达到安全标注的时候，HDFS会自动离开安全模式。
```

#### 5、为什么HDFS不适合存储小文件？

 ```
 1、存储小文件会占用NameNode大量的内存来存储文件目录和块信息。这样是不行的，因为NameNode的内存也是有限的。
 2、小文件存储的寻址时间会超过读取时间，这样违反了HDF的设计目标。
 寻址时间为传输时间的1%，为最佳状态。所以传输时间=10ms/0.01=1000ms=1s，目前普通机械硬盘传输速度为100MB/s，所以block大小=100MB/s*1s=100MB最佳。
 ```

#### 6、HDFS的可靠性策略。

#### 7、HDFS的优缺点。

#### 8、DataNode在什么情况下不会备份？

#### 9、集群中其中一个DataNode出现错误会怎么样？

#### 10、一个DataNode宕机了，怎会恢复？



### 虚拟机启动命令

```bash
# 三台服务器都启动zookeeper
/opt/module/zookeeper-3.4.9/bin/zkServer.sh start

# 查看zookeeper状态
/opt/module/zookeeper-3.4.9/bin/zkServer.sh status

/opt/module/zookeeper-3.4.9/bin/zkServer.sh stop
# hadoop003启动所有服务
start-all.sh

# hadoop001启动resourcemanager
yarn-daemon.sh start resourcemanager

# hadoop001启动hive
hive --service metastore &

# 启动Flink
/opt/module/flink-1.14.0/bin/start-cluster.sh

# 启动kafka
/opt/module/kafka_2.13-2.4.1/sbin/start-kafka.sh

# Flink运行jar包
./flink run -c WordCount001  /data/examples/flink001-1.0-SNAPSHOT.jar --hostname hadoop001 --port 1234
./flink run -c product.HotProduct /data/examples/flink-user-behavior

#vim快速退出
shift + zz 
```

